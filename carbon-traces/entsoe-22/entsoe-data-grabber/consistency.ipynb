{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-29T16:27:11.513639Z",
     "start_time": "2024-11-29T16:27:11.159384Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def granularity_converter(path):\n",
    "    # Read the original parquet file\n",
    "    df = pd.read_parquet(path)\n",
    "    \n",
    "    # Convert the 'timestamp' column to datetime if not already\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    \n",
    "    # Initialize a list to collect new rows\n",
    "    rows = []\n",
    "    \n",
    "    # Loop through each row in the original DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        # Generate four new rows for each entry, adjusting the timestamp by 15 minutes for each\n",
    "        for i in range(4):\n",
    "            new_row = {'timestamp': row['timestamp'] + pd.Timedelta(minutes=15*i),\n",
    "                       'carbon_intensity': row['carbon_intensity'] / 4}\n",
    "            rows.append(new_row)\n",
    "    \n",
    "    # Create a new DataFrame from the list of new rows\n",
    "    new_df = pd.DataFrame(rows)\n",
    "    \n",
    "    # Save the new DataFrame to a parquet file\n",
    "    new_df.to_parquet(path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-29T16:27:26.348772Z",
     "start_time": "2024-11-29T16:27:26.343888Z"
    }
   },
   "id": "69e6c9642f9bee6c",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['carbon_usage.txt',\n 'grabber2.ipynb',\n 'EnergyData.py',\n 'co2_granularity',\n 'variables.py',\n 'util.ipynb',\n '__pycache__',\n 'grabber.ipynb',\n 'consistency.ipynb',\n 'parquets']"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = os.listdir(\".\")\n",
    "all_files"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T21:51:14.327451Z",
     "start_time": "2024-11-28T21:51:14.323112Z"
    }
   },
   "id": "499a0b0167e02964",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Iterate over files and process Parquet files\n",
    "for file in all_files:\n",
    "    if file.endswith(\".parquet\"):\n",
    "        try:\n",
    "            granularity_converter(file)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-27T16:10:53.938703Z",
     "start_time": "2024-11-27T16:10:47.673539Z"
    }
   },
   "id": "554397bb11b67108",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "granularity_converter(\"data/entso-e-IT-2023_1-2023_12.parquet\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-29T16:27:40.569690Z",
     "start_time": "2024-11-29T16:27:40.195844Z"
    }
   },
   "id": "78e60c8ecff31580",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                      timestamp  carbon_intensity\n0     2022-12-31 23:00:00+01:00         47.311868\n1     2022-12-31 23:15:00+01:00         47.311868\n2     2022-12-31 23:30:00+01:00         47.311868\n3     2022-12-31 23:45:00+01:00         47.311868\n4     2023-01-01 00:00:00+01:00         48.484459\n...                         ...               ...\n34939 2023-12-30 21:45:00+01:00         26.454862\n34940 2023-12-30 22:00:00+01:00         26.954670\n34941 2023-12-30 22:15:00+01:00         26.954670\n34942 2023-12-30 22:30:00+01:00         26.954670\n34943 2023-12-30 22:45:00+01:00         26.954670\n\n[34944 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timestamp</th>\n      <th>carbon_intensity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2022-12-31 23:00:00+01:00</td>\n      <td>47.311868</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022-12-31 23:15:00+01:00</td>\n      <td>47.311868</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022-12-31 23:30:00+01:00</td>\n      <td>47.311868</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022-12-31 23:45:00+01:00</td>\n      <td>47.311868</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2023-01-01 00:00:00+01:00</td>\n      <td>48.484459</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>34939</th>\n      <td>2023-12-30 21:45:00+01:00</td>\n      <td>26.454862</td>\n    </tr>\n    <tr>\n      <th>34940</th>\n      <td>2023-12-30 22:00:00+01:00</td>\n      <td>26.954670</td>\n    </tr>\n    <tr>\n      <th>34941</th>\n      <td>2023-12-30 22:15:00+01:00</td>\n      <td>26.954670</td>\n    </tr>\n    <tr>\n      <th>34942</th>\n      <td>2023-12-30 22:30:00+01:00</td>\n      <td>26.954670</td>\n    </tr>\n    <tr>\n      <th>34943</th>\n      <td>2023-12-30 22:45:00+01:00</td>\n      <td>26.954670</td>\n    </tr>\n  </tbody>\n</table>\n<p>34944 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(\"data/entso-e-IT-2023_1-2023_12.parquet\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-29T16:27:41.185165Z",
     "start_time": "2024-11-29T16:27:41.176924Z"
    }
   },
   "id": "6e118b69415bf446",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7e5ba4bd5dc1a51a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# for every file, keep only the timestamps that are in the range of 2023-01-01 00:00:00 to 2023-12-31 23:45:00\n",
    "for file in all_files:\n",
    "    if file.endswith(\".parquet\"):\n",
    "        try:\n",
    "            df = pd.read_parquet(file)\n",
    "            df = df[(df['timestamp'] >= '2023-01-01 00:00:00') & (df['timestamp'] <= '2023-12-31 23:45:00')]\n",
    "            df.to_parquet(file)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-27T16:17:46.551029Z",
     "start_time": "2024-11-27T16:17:46.462129Z"
    }
   },
   "id": "de49bca99a8c80c5",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                      timestamp  carbon_intensity\n0     2023-01-01 00:00:00+01:00        108.917555\n1     2023-01-01 00:15:00+01:00        108.349605\n2     2023-01-01 00:30:00+01:00        106.946341\n3     2023-01-01 00:45:00+01:00        108.492066\n4     2023-01-01 01:00:00+01:00        106.033925\n...                         ...               ...\n34939 2023-12-30 22:45:00+01:00        126.913995\n34940 2023-12-30 23:00:00+01:00        122.441263\n34941 2023-12-30 23:15:00+01:00        122.994395\n34942 2023-12-30 23:30:00+01:00        123.970878\n34943 2023-12-30 23:45:00+01:00        124.886285\n\n[34944 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timestamp</th>\n      <th>carbon_intensity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2023-01-01 00:00:00+01:00</td>\n      <td>108.917555</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2023-01-01 00:15:00+01:00</td>\n      <td>108.349605</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2023-01-01 00:30:00+01:00</td>\n      <td>106.946341</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2023-01-01 00:45:00+01:00</td>\n      <td>108.492066</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2023-01-01 01:00:00+01:00</td>\n      <td>106.033925</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>34939</th>\n      <td>2023-12-30 22:45:00+01:00</td>\n      <td>126.913995</td>\n    </tr>\n    <tr>\n      <th>34940</th>\n      <td>2023-12-30 23:00:00+01:00</td>\n      <td>122.441263</td>\n    </tr>\n    <tr>\n      <th>34941</th>\n      <td>2023-12-30 23:15:00+01:00</td>\n      <td>122.994395</td>\n    </tr>\n    <tr>\n      <th>34942</th>\n      <td>2023-12-30 23:30:00+01:00</td>\n      <td>123.970878</td>\n    </tr>\n    <tr>\n      <th>34943</th>\n      <td>2023-12-30 23:45:00+01:00</td>\n      <td>124.886285</td>\n    </tr>\n  </tbody>\n</table>\n<p>34944 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(\"entso-e-DE-2023_1-2023_12.parquet\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T19:08:39.543514Z",
     "start_time": "2024-11-28T19:08:39.530235Z"
    }
   },
   "id": "34a716d62ad9f297",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mArrowInvalid\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_parquet\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../parquets/entso-e-ME-2023_1-2023_12.parquet\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/parquet.py:667\u001B[0m, in \u001B[0;36mread_parquet\u001B[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001B[0m\n\u001B[1;32m    664\u001B[0m     use_nullable_dtypes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    665\u001B[0m check_dtype_backend(dtype_backend)\n\u001B[0;32m--> 667\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimpl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    668\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    669\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    670\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    671\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    672\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_nullable_dtypes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_nullable_dtypes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    673\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype_backend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype_backend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    674\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilesystem\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilesystem\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    675\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    676\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/parquet.py:274\u001B[0m, in \u001B[0;36mPyArrowImpl.read\u001B[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001B[0m\n\u001B[1;32m    267\u001B[0m path_or_handle, handles, filesystem \u001B[38;5;241m=\u001B[39m _get_path_or_handle(\n\u001B[1;32m    268\u001B[0m     path,\n\u001B[1;32m    269\u001B[0m     filesystem,\n\u001B[1;32m    270\u001B[0m     storage_options\u001B[38;5;241m=\u001B[39mstorage_options,\n\u001B[1;32m    271\u001B[0m     mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    272\u001B[0m )\n\u001B[1;32m    273\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 274\u001B[0m     pa_table \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparquet\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_table\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath_or_handle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    276\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    277\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilesystem\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilesystem\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    278\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    279\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    280\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    281\u001B[0m     result \u001B[38;5;241m=\u001B[39m pa_table\u001B[38;5;241m.\u001B[39mto_pandas(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mto_pandas_kwargs)\n\u001B[1;32m    283\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m manager \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.11/site-packages/pyarrow/parquet/core.py:1762\u001B[0m, in \u001B[0;36mread_table\u001B[0;34m(source, columns, use_threads, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification)\u001B[0m\n\u001B[1;32m   1756\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m   1757\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPassing \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muse_legacy_dataset\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is deprecated as of pyarrow 15.0.0 \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1758\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mand will be removed in a future version.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1759\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m, stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m   1761\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1762\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m \u001B[43mParquetDataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1763\u001B[0m \u001B[43m        \u001B[49m\u001B[43msource\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1764\u001B[0m \u001B[43m        \u001B[49m\u001B[43mschema\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mschema\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1765\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilesystem\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilesystem\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1766\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpartitioning\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpartitioning\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1767\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmemory_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1768\u001B[0m \u001B[43m        \u001B[49m\u001B[43mread_dictionary\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mread_dictionary\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1769\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbuffer_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbuffer_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1770\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1771\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_prefixes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_prefixes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1772\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpre_buffer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpre_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1773\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcoerce_int96_timestamp_unit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcoerce_int96_timestamp_unit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1774\u001B[0m \u001B[43m        \u001B[49m\u001B[43mthrift_string_size_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mthrift_string_size_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1775\u001B[0m \u001B[43m        \u001B[49m\u001B[43mthrift_container_size_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mthrift_container_size_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1776\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpage_checksum_verification\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpage_checksum_verification\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1777\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1778\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[1;32m   1779\u001B[0m     \u001B[38;5;66;03m# fall back on ParquetFile for simple cases when pyarrow.dataset\u001B[39;00m\n\u001B[1;32m   1780\u001B[0m     \u001B[38;5;66;03m# module is not available\u001B[39;00m\n\u001B[1;32m   1781\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m filters \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.11/site-packages/pyarrow/parquet/core.py:1329\u001B[0m, in \u001B[0;36mParquetDataset.__init__\u001B[0;34m(self, path_or_paths, filesystem, schema, filters, read_dictionary, memory_map, buffer_size, partitioning, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification, use_legacy_dataset)\u001B[0m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m single_file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1326\u001B[0m     fragment \u001B[38;5;241m=\u001B[39m parquet_format\u001B[38;5;241m.\u001B[39mmake_fragment(single_file, filesystem)\n\u001B[1;32m   1328\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset \u001B[38;5;241m=\u001B[39m ds\u001B[38;5;241m.\u001B[39mFileSystemDataset(\n\u001B[0;32m-> 1329\u001B[0m         [fragment], schema\u001B[38;5;241m=\u001B[39mschema \u001B[38;5;129;01mor\u001B[39;00m \u001B[43mfragment\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mphysical_schema\u001B[49m,\n\u001B[1;32m   1330\u001B[0m         \u001B[38;5;28mformat\u001B[39m\u001B[38;5;241m=\u001B[39mparquet_format,\n\u001B[1;32m   1331\u001B[0m         filesystem\u001B[38;5;241m=\u001B[39mfragment\u001B[38;5;241m.\u001B[39mfilesystem\n\u001B[1;32m   1332\u001B[0m     )\n\u001B[1;32m   1333\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m   1335\u001B[0m \u001B[38;5;66;03m# check partitioning to enable dictionary encoding\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.11/site-packages/pyarrow/_dataset.pyx:1431\u001B[0m, in \u001B[0;36mpyarrow._dataset.Fragment.physical_schema.__get__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.11/site-packages/pyarrow/error.pxi:154\u001B[0m, in \u001B[0;36mpyarrow.lib.pyarrow_internal_check_status\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.11/site-packages/pyarrow/error.pxi:91\u001B[0m, in \u001B[0;36mpyarrow.lib.check_status\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mArrowInvalid\u001B[0m: Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file."
     ]
    }
   ],
   "source": [
    "pd.read_parquet(\"../parquets/entso-e-ME-2023_1-2023_12.parquet\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T19:09:39.378540Z",
     "start_time": "2024-11-28T19:09:39.345112Z"
    }
   },
   "id": "8a34b2a2e943448d",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8d9b7e1543a9fd93"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
